}
na_tab = na_get(d)
na_tab
# check for constant values
const <- apply(d %>% select(-y), 2, function(x) length(unique(x))==1)
#table(const)
d <- d %>% select(-names(X)[const])
# ============================================================================
# === K-FOLD CROSS-VALIDATION REGRESSION
# ============================================================================
# create 5 balanced folds: 4 train vs 1 test
# evaluate with RMSE MAE R2
# ----------------------------------------------------------------------------
# --- FOLDS AND METRICS
# ----------------------------------------------------------------------------
set.seed(1234)
K <- 5
n <- nrow(d)
fold_ids <- sample(rep(1:K, length.out = n))
compute_metrics <- function(pred, actual) {
rmse <- sqrt(mean((pred - actual)^2))
mae <- mean(abs(pred - actual))
r2 <- 1 - sum((actual - pred)^2) / sum((actual - mean(actual))^2)
c(RMSE = rmse, MAE = mae, R2 = r2)
}
# initialise results lists
cv_results <- list()
predictions_all <- list()
for (k in 1:K) {
cat("--- FOLD", k, "/", K, "---\n")
# split train/test
test_idx <- which(fold_ids == k)
train_idx <- which(fold_ids != k)
train <- d[train_idx,]
test <- d[test_idx,]
# X e y
y_train <- train$y
X_train <- train %>% select(-y)
y_test <- test$y
X_test <- test %>% select(-y)
# glmnet matrix
X_train_mat <- as.matrix(X_train)
X_test_mat <- as.matrix(X_test)
# initialise predictions
fold_predictions <- list()
fold_predictions$y_true <- y_test
fold_predictions$fold <- k
# -------------------------
# ---   LINEAR MODEL    ---
# -------------------------
lm_model <- lm(y ~ ., data = train)
fold_predictions$lm <- predict(lm_model, newdata = test)
# -----------------------------
# ---   RIDGE REGRESSION    ---
# -----------------------------
cv_ridge <- cv.glmnet(X_train_mat, y_train, alpha = 0, nfolds = 5)
fold_predictions$ridge <- as.vector(predict(cv_ridge, s = "lambda.min", newx = X_test_mat))
# ------------------
# ---   LASSO    ---
# ------------------
cv_lasso <- cv.glmnet(X_train_mat, y_train, alpha = 1, nfolds = 5)
fold_predictions$lasso <- as.vector(predict(cv_lasso, s = "lambda.min", newx = X_test_mat))
# ---------------------------
# ---   ADAPTIVE LASSO    ---
# ---------------------------
ridge_coefs <- coef(cv_ridge, s = "lambda.min")[-1]
weights <- 1 / (abs(ridge_coefs) + 1e-10)
cv_alasso <- cv.glmnet(X_train_mat, y_train, alpha = 1,
penalty.factor = weights, nfolds = 5)
fold_predictions$alasso <- as.vector(predict(cv_alasso, s = "lambda.min", newx = X_test_mat))
# ------------------------
# ---   ELASTIC NET    ---
# ------------------------
cv_enet <- cv.glmnet(X_train_mat, y_train, alpha = 0.5, nfolds = 5)
fold_predictions$enet <- as.vector(predict(cv_enet, s = "lambda.min", newx = X_test_mat))
# ----------------------------
# ---   REGRESSION TREE    ---
# ----------------------------
tree_model <- rpart(y ~ ., data = train,
control = rpart.control(cp = 0.001, xval = 10))
cp_opt <- tree_model$cptable[which.min(tree_model$cptable[, "xerror"]), "CP"]
tree_pruned <- prune(tree_model, cp = cp_opt)
fold_predictions$tree <- predict(tree_pruned, newdata = test)
# -----------------
# ---   MARS    ---
# -----------------
mars_model <- earth(y ~ ., data = train, degree = 2, nfold = 5)
fold_predictions$mars <- as.vector(predict(mars_model, newdata = test))
# ----------------
# ---   PPR    ---
# ----------------
ppr_model <- ppr(y ~ ., data = train, nterms = 3, max.terms = 10)
fold_predictions$ppr <- predict(ppr_model, newdata = test)
# --------------------------
# ---   RANDOM FOREST    ---
# --------------------------
rf_model <- randomForest(y ~ ., data = train, ntree = 500,
mtry = max(floor(ncol(X_train) / 3), 1))
fold_predictions$rf <- predict(rf_model, newdata = test)
# -------------------
# ---   RANGER    ---
# -------------------
ranger_model <- ranger(y ~ ., data = train, num.trees = 500,
mtry = max(floor(ncol(X_train) / 3), 1))
fold_predictions$ranger <- predict(ranger_model, data = test)$predictions
# --------------------
# ---   XGBOOST    ---
# --------------------
dtrain <- xgb.DMatrix(data = X_train_mat, label = y_train)
dtest <- xgb.DMatrix(data = X_test_mat, label = y_test)
params_xgb <- list(
objective = "reg:squarederror",
learning_rate = 0.1,
max_depth = 6
)
cv_xgb <- xgb.cv(
params = params_xgb,
data = dtrain,
nrounds = 300,
nfold = 5,
early_stopping_rounds = 20,
verbose = 0
)
best_iter_xgb <- ifelse(!is.null(cv_xgb$best_iteration) && cv_xgb$best_iteration > 0,
cv_xgb$best_iteration, 300)
xgb_model <- xgb.train(
params = params_xgb,
data = dtrain,
nrounds = cv_xgb$best_iteration,
verbose = 0
)
fold_predictions$xgb <- predict(xgb_model, dtest)
# --------------------
# ---   LIGHTGBM   ---
# --------------------
lgb_train <- lgb.Dataset(data = X_train_mat, label = y_train)
lgb_test <- lgb.Dataset(data = X_test_mat, label = y_test)
params_lgb <- list(
objective = "regression",
metric = "rmse",
learning_rate = 0.1,
num_leaves = 31,
feature_fraction = 0.8,
verbose = -1
)
lgb_model <- lgb.train(
params = params_lgb,
data = lgb_train,
nrounds = 300,
valids = list(test = lgb_test),
early_stopping_rounds = 20,
verbose = -1
)
fold_predictions$lgb <- predict(lgb_model, X_test_mat)
# save predictions
predictions_all[[k]] <- fold_predictions
cat("\n")
}
rm(list=ls())
setwd("C:/Users/enric/OneDrive/Desktop/NewJob/Python_projects/data/wineQuality")
wine <- read.csv("winequality-white.csv", sep = ";")
str(wine); summary(wine)
X <- wine[,-12]
# target
summary(wine$quality)
par(mfrow = c(1,2))
hist(wine$quality, breaks = 10, main = "", xlab = "Original scale", ylab = "")
hist(log(wine$quality), breaks = 10, main = "", xlab = "Log scale", ylab = "")
par(mfrow = c(1,1))
y <- wine$quality
d <- cbind(y, X)
# check for NA's
na_get = function(data){
na_vars = sapply(data, function(col)sum(is.na(col)))
na_vars = sort(na_vars[na_vars>0])
na_vars = data.frame(variabile=names(na_vars),freq_assoluta=as.numeric(na_vars),
freq_relativa=round(as.numeric(na_vars)/nrow(data),4))
na_vars
}
na_tab = na_get(d)
na_tab
# check for constant values
const <- apply(d %>% select(-y), 2, function(x) length(unique(x))==1)
#table(const)
d <- d %>% select(-names(X)[const])
# ============================================================================
# === K-FOLD CROSS-VALIDATION REGRESSION
# ============================================================================
# create 5 balanced folds: 4 train vs 1 test
# evaluate with RMSE MAE R2
# ----------------------------------------------------------------------------
# --- FOLDS AND METRICS
# ----------------------------------------------------------------------------
set.seed(1234)
K <- 5
n <- nrow(d)
fold_ids <- sample(rep(1:K, length.out = n))
compute_metrics <- function(pred, actual) {
rmse <- sqrt(mean((pred - actual)^2))
mae <- mean(abs(pred - actual))
r2 <- 1 - sum((actual - pred)^2) / sum((actual - mean(actual))^2)
c(RMSE = rmse, MAE = mae, R2 = r2)
}
# initialise results lists
cv_results <- list()
predictions_all <- list()
for (k in 1:K) {
cat("--- FOLD", k, "/", K, "---\n")
# split train/test
test_idx <- which(fold_ids == k)
train_idx <- which(fold_ids != k)
train <- d[train_idx,]
test <- d[test_idx,]
# X e y
y_train <- train$y
X_train <- train %>% select(-y)
y_test <- test$y
X_test <- test %>% select(-y)
# glmnet matrix
X_train_mat <- as.matrix(X_train)
X_test_mat <- as.matrix(X_test)
# initialise predictions
fold_predictions <- list()
fold_predictions$y_true <- y_test
fold_predictions$fold <- k
# -------------------------
# ---   LINEAR MODEL    ---
# -------------------------
lm_model <- lm(y ~ ., data = train)
fold_predictions$lm <- predict(lm_model, newdata = test)
# -----------------------------
# ---   RIDGE REGRESSION    ---
# -----------------------------
cv_ridge <- cv.glmnet(X_train_mat, y_train, alpha = 0, nfolds = 5)
fold_predictions$ridge <- as.vector(predict(cv_ridge, s = "lambda.min", newx = X_test_mat))
# ------------------
# ---   LASSO    ---
# ------------------
cv_lasso <- cv.glmnet(X_train_mat, y_train, alpha = 1, nfolds = 5)
fold_predictions$lasso <- as.vector(predict(cv_lasso, s = "lambda.min", newx = X_test_mat))
# ---------------------------
# ---   ADAPTIVE LASSO    ---
# ---------------------------
ridge_coefs <- coef(cv_ridge, s = "lambda.min")[-1]
weights <- 1 / (abs(ridge_coefs) + 1e-10)
cv_alasso <- cv.glmnet(X_train_mat, y_train, alpha = 1,
penalty.factor = weights, nfolds = 5)
fold_predictions$alasso <- as.vector(predict(cv_alasso, s = "lambda.min", newx = X_test_mat))
# ------------------------
# ---   ELASTIC NET    ---
# ------------------------
cv_enet <- cv.glmnet(X_train_mat, y_train, alpha = 0.5, nfolds = 5)
fold_predictions$enet <- as.vector(predict(cv_enet, s = "lambda.min", newx = X_test_mat))
# ----------------------------
# ---   REGRESSION TREE    ---
# ----------------------------
tree_model <- rpart(y ~ ., data = train,
control = rpart.control(cp = 0.001, xval = 10))
cp_opt <- tree_model$cptable[which.min(tree_model$cptable[, "xerror"]), "CP"]
tree_pruned <- prune(tree_model, cp = cp_opt)
fold_predictions$tree <- predict(tree_pruned, newdata = test)
# -----------------
# ---   MARS    ---
# -----------------
mars_model <- earth(y ~ ., data = train, degree = 2, nfold = 5)
fold_predictions$mars <- as.vector(predict(mars_model, newdata = test))
# ----------------
# ---   PPR    ---
# ----------------
ppr_model <- ppr(y ~ ., data = train, nterms = 3, max.terms = 10)
fold_predictions$ppr <- predict(ppr_model, newdata = test)
# --------------------------
# ---   RANDOM FOREST    ---
# --------------------------
rf_model <- randomForest(y ~ ., data = train, ntree = 500,
mtry = max(floor(ncol(X_train) / 3), 1))
fold_predictions$rf <- predict(rf_model, newdata = test)
# -------------------
# ---   RANGER    ---
# -------------------
ranger_model <- ranger(y ~ ., data = train, num.trees = 500,
mtry = max(floor(ncol(X_train) / 3), 1))
fold_predictions$ranger <- predict(ranger_model, data = test)$predictions
# --------------------
# ---   XGBOOST    ---
# --------------------
dtrain <- xgb.DMatrix(data = X_train_mat, label = y_train)
dtest <- xgb.DMatrix(data = X_test_mat, label = y_test)
params_xgb <- list(
objective = "reg:squarederror",
learning_rate = 0.1,
max_depth = 6
)
cv_xgb <- xgb.cv(
params = params_xgb,
data = dtrain,
nrounds = 300,
nfold = 5,
early_stopping_rounds = 20,
verbose = 0
)
best_iter_xgb <- ifelse(!is.null(cv_xgb$best_iteration) && cv_xgb$best_iteration > 0,
cv_xgb$best_iteration, 300)
xgb_model <- xgb.train(
params = params_xgb,
data = dtrain,
nrounds = best_iter_xgb,
verbose = 0
)
fold_predictions$xgb <- predict(xgb_model, dtest)
# --------------------
# ---   LIGHTGBM   ---
# --------------------
lgb_train <- lgb.Dataset(data = X_train_mat, label = y_train)
lgb_test <- lgb.Dataset(data = X_test_mat, label = y_test)
params_lgb <- list(
objective = "regression",
metric = "rmse",
learning_rate = 0.1,
num_leaves = 31,
feature_fraction = 0.8,
verbose = -1
)
lgb_model <- lgb.train(
params = params_lgb,
data = lgb_train,
nrounds = 300,
valids = list(test = lgb_test),
early_stopping_rounds = 20,
verbose = -1
)
fold_predictions$lgb <- predict(lgb_model, X_test_mat)
# save predictions
predictions_all[[k]] <- fold_predictions
cat("\n")
}
# Models list
model_names <- names(predictions_all[[1]])
model_names <- model_names[!model_names %in% c("y_true", "fold")]
# Calculate metrics combining folds
cv_summary <- map_dfr(model_names, function(model) {
# predictions and true values
all_preds <- map_dbl(predictions_all, ~ .x[[model]]) %>% unlist()
all_true <- map_dbl(predictions_all, ~ .x$y_true) %>% unlist()
# global metrics
global_metrics <- compute_metrics(all_preds, all_true)
# metrics per fold
fold_metrics <- map_dfr(1:K, function(k) {
preds <- predictions_all[[k]][[model]]
true <- predictions_all[[k]]$y_true
metrics <- compute_metrics(preds, true)
as_tibble_row(metrics)
})
tibble(
Model = model,
RMSE_mean = mean(fold_metrics$RMSE),
RMSE_sd = sd(fold_metrics$RMSE),
MAE_mean = mean(fold_metrics$MAE),
MAE_sd = sd(fold_metrics$MAE),
R2_mean = mean(fold_metrics$R2),
R2_sd = sd(fold_metrics$R2),
RMSE_global = global_metrics["RMSE"]
)
}) %>%
arrange(RMSE_mean)
# Models list
model_names <- names(predictions_all[[1]])
model_names <- model_names[!model_names %in% c("y_true", "fold")]
# Calculate metrics combining folds
cv_summary <- map_dfr(model_names, function(model) {
# predictions and true values
all_preds <- map(predictions_all, ~ .x[[model]]) %>% unlist()
all_true <- map(predictions_all, ~ .x$y_true) %>% unlist()
#global metrics
global_metrics <- compute_metrics(all_preds, all_true)
# metrics per fold
fold_metrics <- map_dfr(1:K, function(k) {
preds <- predictions_all[[k]][[model]]
true <- predictions_all[[k]]$y_true
metrics <- compute_metrics(preds, true)
as_tibble_row(metrics)
})
tibble(
Model = model,
RMSE_mean = mean(fold_metrics$RMSE),
RMSE_sd = sd(fold_metrics$RMSE),
MAE_mean = mean(fold_metrics$MAE),
MAE_sd = sd(fold_metrics$MAE),
R2_mean = mean(fold_metrics$R2),
R2_sd = sd(fold_metrics$R2),
RMSE_global = global_metrics["RMSE"]
)
}) %>%
arrange(RMSE_mean)
model_labels <- c(
lm = "Linear Model",
ridge = "Ridge",
lasso = "Lasso",
alasso = "Adaptive Lasso",
enet = "Elastic Net",
tree = "Regression Tree",
mars = "MARS",
ppr = "PPR",
rf = "Random Forest",
ranger = "Ranger RF",
xgb = "XGBoost",
lgb = "LightGBM"
)
cv_summary <- cv_summary %>%
mutate(Model_Label = model_labels[Model])
# Results
print(cv_summary %>%
select(Model_Label, RMSE_mean, RMSE_sd, MAE_mean, R2_mean) %>%
rename(Model = Model_Label,
`RMSE (mean)` = RMSE_mean,
`RMSE (sd)` = RMSE_sd,
`MAE (mean)` = MAE_mean,
`R² (mean)` = R2_mean),
n = Inf)
# best model
best_model <- cv_summary$Model_Label[1]
best_rmse <- cv_summary$RMSE_mean[1]
best_sd <- cv_summary$RMSE_sd[1]
cat("\n Best model:", best_model, "\n")
cat("   Mean RMSE:", round(best_rmse, 4), "±", round(best_sd, 4), "\n\n")
# Plot 1: RMSE and errors comparison
p1 <- cv_summary %>%
mutate(Model_Label = fct_reorder(Model_Label, RMSE_mean)) %>%
ggplot(aes(x = Model_Label, y = RMSE_mean)) +
geom_col(fill = "steelblue", alpha = 0.7) +
geom_errorbar(aes(ymin = RMSE_mean - RMSE_sd,
ymax = RMSE_mean + RMSE_sd),
width = 0.3, color = "darkred") +
coord_flip() +
labs(title = "Confronto modelli - RMSE medio (5-fold CV)",
subtitle = "Barre di errore = ± 1 SD",
x = NULL, y = "RMSE medio") +
theme_minimal() +
theme(plot.title = element_text(face = "bold"))
print(p1)
# Plot 2: Boxplot RMSE by fold
rmse_by_fold <- map_dfr(model_names, function(model) {
map_dfr(1:K, function(k) {
preds <- predictions_all[[k]][[model]]
true <- predictions_all[[k]]$y_true
rmse <- sqrt(mean((preds - true)^2))
tibble(Model = model_labels[model], Fold = k, RMSE = rmse)
})
})
p2 <- rmse_by_fold %>%
mutate(Model = fct_reorder(Model, RMSE, .fun = mean)) %>%
ggplot(aes(x = Model, y = RMSE)) +
geom_boxplot(fill = "lightblue", alpha = 0.7) +
geom_point(alpha = 0.5, position = position_jitter(width = 0.1)) +
coord_flip() +
labs(title = "Distribuzione RMSE across folds",
x = NULL, y = "RMSE") +
theme_minimal() +
theme(plot.title = element_text(face = "bold"))
print(p2)
best_model_code <- cv_summary$Model[1]
X_full <- d %>% select(-y)
y_full <- d$y
X_full_mat <- as.matrix(X_full)
final_model <- switch(
best_model_code,
lm = lm(y ~ ., data = d),
ridge = {
cv.glmnet(X_full_mat, y_full, alpha = 0, nfolds = 5)
},
lasso = {
cv.glmnet(X_full_mat, y_full, alpha = 1, nfolds = 5)
},
alasso = {
cv_r <- cv.glmnet(X_full_mat, y_full, alpha = 0, nfolds = 5)
w <- 1 / (abs(coef(cv_r, s = "lambda.min")[-1]) + 1e-10)
cv.glmnet(X_full_mat, y_full, alpha = 1, penalty.factor = w, nfolds = 5)
},
enet = {
cv.glmnet(X_full_mat, y_full, alpha = 0.5, nfolds = 5)
},
tree = {
t <- rpart(y ~ ., data = d, control = rpart.control(cp = 0.001, xval = 10))
prune(t, cp = t$cptable[which.min(t$cptable[, "xerror"]), "CP"])
},
mars = earth(y ~ ., data = d, degree = 2, nfold = 5),
ppr = ppr(y ~ ., data = d, nterms = 3, max.terms = 10),
rf = randomForest(y ~ ., data = d, ntree = 500),
ranger = ranger(y ~ ., data = d, num.trees = 500),
xgb = {
dtrain_full <- xgb.DMatrix(data = X_full_mat, label = y_full)
params_xgb_full <- list(
objective = "reg:squarederror",
learning_rate = 0.1,
max_depth = 6
)
cv_xgb_full <- xgb.cv(params = params_xgb_full, data = dtrain_full,
nrounds = 300, nfold = 5,
early_stopping_rounds = 20, verbose = 0)
xgb.train(params = params_xgb_full, data = dtrain_full,
nrounds = cv_xgb_full$best_iteration, verbose = 0)
},
lgb = {
lgb_full <- lgb.Dataset(data = X_full_mat, label = y_full)
lgb.train(params = list(objective = "regression", metric = "rmse",
learning_rate = 0.1, num_leaves = 31, verbose = -1),
data = lgb_full, nrounds = 300, nfold = 5,
early_stopping_rounds = 20, verbose = -1)
}
)
final_model
summary(final_model)
